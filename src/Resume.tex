\documentclass[a4paper]{Resume}

\usepackage[x11names]{xcolor}
\color{black}

\begin{document}
	
\setPageColour{white}
\setHeaderAlignment{left}
\setHeadingColours{SlateGray3}
\setContactLocation{opposite}
\vspace{-0.5em}  % Reduce space after header
\setYourName{Patrick Harned}
\setYourJobTitle{Data Scientist/ML Engineer}
\setYourMobileNo{347-263-0441}
\setYourEmailAddr{pwharned@gmail.com}
\setYourWebAddr{pwharned.github.io/Resume/}

\showHeader
\setSectionAlignment{left}

\personalStatement{ML Engineer/Data Scientist with 6+ years developing evaluation infrastructure and production ML systems.}

\nopagebreak
% Two-column layout using minipage
\nopagebreak

\noindent\begin{minipage}[t]{0.28\textwidth}

\compactHeading{Technical Skills}

\textbf{Languages (Experienced) } \\
Python, Scala, Java, C/C++, SQL

\vspace{0.5em}
\textbf{ML} \\
PyTorch, cudNN, Spark

\vspace{0.5em}
\textbf{Infrastructure} \\
Kubernetes,\\
OpenShift Container Platform

\vspace{0.5em}
\textbf{Databases \& Data} \\
Db2, PostgreSQL, Elasticsearch, Lance DB

\vspace{0.5em}
\textbf{Development} \\
MCP, REST, gRPC

\vspace{1em}

\compactHeading{Education}

\compactEducation{2019}{Dual Masters}{Applied Statistics, UT Austin}

\compactEducation{2015}{BA, Classical Languages}{Hunter College, CUNY}

\vspace{1em}



\compactHeading{Languages}

\begin{itemize}[leftmargin=*, itemsep=2pt]
	\item English (Native)
	\item Arabic (Professional)
	\item Japanese (N2)
\end{itemize}

\end{minipage}%
\hfill
\begin{minipage}[t]{0.68\textwidth}

\compactHeading{Professional Experience}

\compactRole{2021 -- Present}
{ML Engineer \& Data Scientist}
{IBM Expert Labs}
{Develop AI solutions and tooling and support production deployment systems for enterprise clients.}

\textbf{AI Agent Evaluation System}

\compactAchievements{Develop Agentic procurement platform integrating Dun Bradstreet data with ERP systems (Ariba, Workday). Implemented qualtiy assurance tracking tool to track execution accuracy, response grounding, and task completion rates using Langfuse and custom tooling.}
{Built observability layer using Prometheus/Db2 for tracking agent behavior and performance in production. Real time monitoring of Precision/Recall for NAICS/UNSPC semantic search.}
{Created automated testing pipelines for input validation and edge case handling. Integrated evaluation metrics into CI/CD workflow}
{Evaluated performance of RAG}

\textbf{LLM Serving Infrastructure on OpenShift AI}

\compactAchievements{Managed MAAS ( Model as a Service) platform deployed to Openshift. Used Nvidia GPU Operator to split 8 H200 GPUs and automate assignment of models to MIG instances.}
{Built scheduling logic for optimal GPU allocation across concurrent inference workloads. }
{Deployed and managed various Llama models as well as GPU accelerated TTS, reranker and embedding models to serve upstream APIs}
{Built Grafana dashboards  and PromQL queries for tracking token and GPU consumption, accuracy across various use cases}

\textbf{Model Evaluation \& Testing Framework}

\compactAchievements{Built evaluation platform in Scala/C++ for standardized model testing across ML projects. Implemented in-db SIMD accelerated metrics for accuracy, bias detection, and performance consistency}
{Implemented continuous evaluation system detecting model drift and data quality issues. Built automated testing for new model versions before production deployment}
{Implemented in-database analytics functions in C++ for Db2 MPP cluster processing multi-terabyte datasets. Optimized query performance for parallel data processing workloads}
{}


\compactRole{2019 -- 2020}
{ML Engineer}
{IBM Cloud Pak Acceleration Team}
{Developed containerized ML applications and deployment pipelines on OpenShift.}

\compactAchievements{Built MLOps pipeline using Kubeflow on OpenShift for model training and deployment. Implemented A/B testing framework for model evaluation in production}
{Developed Scala microservices for ML model serving with authentication and rate limiting. Deployed containerized applications on Kubernetes handling production inference workloads}
{Created data integration pipelines connecting federated Db2 warehouse with external data sources (MySQL, Hive) for feature engineering}
{}

\compactRole{2018 -- 2019}
{Data Specialist}
{Princeton University}
{Built data quality and statistical analysis pipelines for research projects.}

\compactAchievements{Developed automated data validation system in Python and R for survey data quality assessment.}
{Built ETL pipelines for data cleaning and standardization. Created reproducible analysis workflows supporting research publications}
{Implemented statistical methods for anomaly detection and consistency checking. Conducted regression and clustering analysis on survey datasets}
{}
\end{minipage}

\end{document}
